---
title: "Sparser is better: one step closer to word embedding interpretability"
collection: publications
permalink: /publication/2023-06-20-45097International Conference of Computational Semantics 2023 (IWCS)
excerpt: 'Sparse word embeddings models (SPINE\, SINr) are designed to embed words in interpretable dimensions. An interpretable dimension is such that a human can interpret the semantic (or syntactic) relations between words active for a dimension. These models are useful for critical downstream tasks in natural language processing (e.g. medical or legal NLP)\, and digital humanities applications. This work extends interpretability at the vector level with a more manageable number of activated dimensions following recommendations from psycholinguistics. Subsequently\, one of the key criteria to an interpretable model is sparsity: in order to be interpretable\, not every word should be represented by all the features of the model\, especially if humans have to interpret these features and their relations. This raises one question: to which extent is sparsity sustainable with regard to performance? We thus introduce a sparsification procedure to evaluate its impact on two interpretable methods (SPINE and SINr) to tend towards sustainable vector interpretability. We also introduce stability as a new criterion to interpretability. Our stability evaluations show little albeit non-zero variation for SPINE and SINr embeddings. We then show that increasing sparsity does not necessarily interfere with performance. These results are encouraging and pave the way towards intrinsically interpretable word vectors.,Les modèles éparses de plongements lexicaux (SPINE\, SINr) ont pour objectif de plonger les mots dans des espaces de représentation aux dimensions interprétables. Une dimension est interprétable dès lors qu&apos;un locuteur peut saisir la cohérence sémantique ou syntaxique des mots activés pour une dimension. Ces modèles sont utiles dans des cadres critiques d&apos;utilisation du traitement automatique de la langue naturel (comme le TAL pour applications médicales ou juridiques)\, et pour des utilisations en humanités numériques. Ce travail vise à étendre la notion d&apos;interprétabilité vers l&apos;interprétabilité des vecteurs de mots en restreignant la quantité de dimensions à considérer depuis des contraintes psycholinguistiques. Ainsi\, l&apos;éparsité (ou la parcimonie) des modèles interprétables est un point clé : pour garantir cette interprétabilité\, tous les mots ne doivent pas être représentés par toutes les dimensions du modèle\, particulièrement dans l&apos;optique de la mise en relation de ces dimensions par des locuteurs. La question du compromis entre l&apos;éparsité et les performances se pose donc. Nous introduisons une procédure d&apos;éparsification pour évaluer son impact sur deux méthodes interprétables (SPINE et SINr) avec l&apos;objectif de déplacer la notion d&apos;interprétabilité vers les vecteurs de mots. Nous proposons également d&apos;introduire la stabilité comme critère supplémentaire à l&apos;interprétabilité. Nos évaluations de stabilité indique une variabilité faible quoi que non nulle pour les vecteurs de SPINE et de SINr. Nous montrons ensuite qu&apos;une éparsité plus importante n&apos;implique pas nécessairement de perte en performance. Ces résultats sont encourageants et participe de la construction de vecteurs de mots interprétables.'
date: 2023-06-20
venue: 'International Conference of Computational Semantics 2023 (IWCS)'
paperurl: 'https://hal.science/hal-04321407/document'
citation: '<i>International Conference of Computational Semantics 2023 (IWCS)</i>, Jun 2023, Nancy, France. pp.106-115'
---
Sparse word embeddings models (SPINE\, SINr) are designed to embed words in interpretable dimensions. An interpretable dimension is such that a human can interpret the semantic (or syntactic) relations between words active for a dimension. These models are useful for critical downstream tasks in natural language processing (e.g. medical or legal NLP)\, and digital humanities applications. This work extends interpretability at the vector level with a more manageable number of activated dimensions following recommendations from psycholinguistics. Subsequently\, one of the key criteria to an interpretable model is sparsity: in order to be interpretable\, not every word should be represented by all the features of the model\, especially if humans have to interpret these features and their relations. This raises one question: to which extent is sparsity sustainable with regard to performance? We thus introduce a sparsification procedure to evaluate its impact on two interpretable methods (SPINE and SINr) to tend towards sustainable vector interpretability. We also introduce stability as a new criterion to interpretability. Our stability evaluations show little albeit non-zero variation for SPINE and SINr embeddings. We then show that increasing sparsity does not necessarily interfere with performance. These results are encouraging and pave the way towards intrinsically interpretable word vectors.,Les modèles éparses de plongements lexicaux (SPINE\, SINr) ont pour objectif de plonger les mots dans des espaces de représentation aux dimensions interprétables. Une dimension est interprétable dès lors qu&apos;un locuteur peut saisir la cohérence sémantique ou syntaxique des mots activés pour une dimension. Ces modèles sont utiles dans des cadres critiques d&apos;utilisation du traitement automatique de la langue naturel (comme le TAL pour applications médicales ou juridiques)\, et pour des utilisations en humanités numériques. Ce travail vise à étendre la notion d&apos;interprétabilité vers l&apos;interprétabilité des vecteurs de mots en restreignant la quantité de dimensions à considérer depuis des contraintes psycholinguistiques. Ainsi\, l&apos;éparsité (ou la parcimonie) des modèles interprétables est un point clé : pour garantir cette interprétabilité\, tous les mots ne doivent pas être représentés par toutes les dimensions du modèle\, particulièrement dans l&apos;optique de la mise en relation de ces dimensions par des locuteurs. La question du compromis entre l&apos;éparsité et les performances se pose donc. Nous introduisons une procédure d&apos;éparsification pour évaluer son impact sur deux méthodes interprétables (SPINE et SINr) avec l&apos;objectif de déplacer la notion d&apos;interprétabilité vers les vecteurs de mots. Nous proposons également d&apos;introduire la stabilité comme critère supplémentaire à l&apos;interprétabilité. Nos évaluations de stabilité indique une variabilité faible quoi que non nulle pour les vecteurs de SPINE et de SINr. Nous montrons ensuite qu&apos;une éparsité plus importante n&apos;implique pas nécessairement de perte en performance. Ces résultats sont encourageants et participe de la construction de vecteurs de mots interprétables.

[Download paper here](https://hal.science/hal-04321407/document)

Recommended citation: <i>International Conference of Computational Semantics 2023 (IWCS)</i>, Jun 2023, Nancy, France. pp.106-115