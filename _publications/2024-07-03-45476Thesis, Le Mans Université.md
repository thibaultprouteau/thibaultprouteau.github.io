---
title: "Graphs, Words, and Communities : converging paths to interpretability with a frugal embedding framework,"
collection: publications
permalink: /publication/2024-07-03-45476Thesis, Le Mans Université
excerpt: 'Representation learning with word and graph embedding models allows distributed representations of information that can in turn be used in input of machine learning algorithms. Through the last two decades\, the tasks of embedding graphs’ nodes and words have shifted from matrix factorization approaches that could be trained in a matter of minutes to large models requiring ever larger quantities of training data and sometimes weeks on large hardware architectures. However\, in a context of global warming where sustainability is a critical concern\, we ought to look back to previous approaches and consider their performances with regard to resources consumption. Furthermore\, with the growing involvement of embeddings in sensitive machine learning applications (judiciary system\, health)\, the need for more interpretable and explainable representations has manifested. To foster efficient representation learning and interpretability\, this thesis introduces Lower Dimension Bipartite Graph Framework (LDBGF)\, a node embedding framework able to embed with the same pipeline graph data and text from large corpora represented as co-occurrence networks. Within this framework\, we introduce two implementations (SINr-NR\, SINr-MF) that leverage community detection in networks to uncover a latent embedding space where items (nodes/words) are represented according to their links to communities. We show that SINr-NR and SINr-MF can compete with similar embedding approaches on tasks such as predicting missing links in networks (link prediction) or node features (degree centrality\, PageRank score). Regarding word embeddings\, we show that SINr-NR is a good contender to represent words via word co-occurrence networks. Finally\, we demonstrate the interpretability of SINr-NR on multiple aspects. First with a human evaluation that shows that SINr-NR’s dimensions are to some extent interpretable. Secondly\, by investigating sparsity of vectors\, and how having fewer dimensions may allow interpreting how the dimensions combine and allow sense to emerge.,L&apos;apprentissage de représentations au travers des méthodes de plongements de mots (word embedding) et de graphes (graph embedding) permet des représentations distribuées de l&apos;information. Ces représentations peuvent à leur tour être utilisées en entrée d&apos;algorithmes d&apos;apprentissage automatique. Au cours des deux dernières décennies\, les tâches de plongement de nœuds et de mots sont passées d&apos;approches par factorisation matricielle qui pouvaient être réalisées en quelques minutes à de grands modèles nécessitant des quantités toujours plus importantes de données d’apprentissage et parfois des semaines sur de grandes architectures matérielles. Toutefois\, dans un contexte de réchauffement climatique où la durabilité est une préoccupation essentielle\, il peut être souhaitable de revenir à des méthodes plus frugales comme elles pouvaient l’être par le passé. En outre\, avec l&apos;implication croissante des plongements dans des applications sensibles de l’apprentissage automatique (système judiciaire\, santé)\, le besoin de représentations plus interprétables et explicables s&apos;est manifesté. Pour favoriser l&apos;apprentissage de représentations efficaces et l&apos;interprétabilité\, cette thèse présente Lower Dimension Bipartite Graph Framework (LDBGF)\, un framework de plongements de nœuds capable d’extraire une représentation vectorielle avec le même pipeline de traitement\, à condition que les données proviennent d’un graphe ou de texte issu de grands corpus représentés sous forme de réseaux de cooccurrence. Dans ce cadre\, nous présentons deux implémentations (SINr- NR\, SINr-MF) qui tirent parti de la détection des communautés dans les réseaux pour découvrir un espace latent dans lequel les éléments (nœuds/mots) sont représentés en fonction de leurs liens avec les communautés. Nous montrons que SINr-NR et SINr-MF peuvent rivaliser avec des approches de plongements concurrentes sur des tâches telles que la prédiction des liens manquants dans les réseaux (link prediction) ou certaines caractéristiques des nœuds (centralité de degré\, score PageRank). En ce qui concerne les plongements de mots\, nous montrons que SINr-NR est un bon candidat pour représenter les mots en utilisant les réseaux de cooccurrences de mots. Enfin\, nous démontrons l&apos;interprétabilité de SINr-NR sur plusieurs aspects. Tout d&apos;abord\, une évaluation humaine montre que les dimensions de SINr-NR sont dans une certaine mesure interprétables. Ensuite\, nous étudions la parcimonie des vecteurs. Notamment\, combien un nombre réduit de dimensions peut permettre d&apos;interpréter comment ces dernières se combinent et permettent de dégager un sens.'
date: 2024-07-03
venue: 'Thesis, Le Mans Université'
paperurl: 'https://theses.hal.science/tel-04696544/document'
citation: 'Machine Learning [cs.LG]. Le Mans Université, 2024. English. <a target=&quot;_blank&quot; href=&quot;https://www.theses.fr/2024LEMA1006&quot;>&amp;#x27E8;NNT : 2024LEMA1006&amp;#x27E9;</a>'
---
Representation learning with word and graph embedding models allows distributed representations of information that can in turn be used in input of machine learning algorithms. Through the last two decades\, the tasks of embedding graphs’ nodes and words have shifted from matrix factorization approaches that could be trained in a matter of minutes to large models requiring ever larger quantities of training data and sometimes weeks on large hardware architectures. However\, in a context of global warming where sustainability is a critical concern\, we ought to look back to previous approaches and consider their performances with regard to resources consumption. Furthermore\, with the growing involvement of embeddings in sensitive machine learning applications (judiciary system\, health)\, the need for more interpretable and explainable representations has manifested. To foster efficient representation learning and interpretability\, this thesis introduces Lower Dimension Bipartite Graph Framework (LDBGF)\, a node embedding framework able to embed with the same pipeline graph data and text from large corpora represented as co-occurrence networks. Within this framework\, we introduce two implementations (SINr-NR\, SINr-MF) that leverage community detection in networks to uncover a latent embedding space where items (nodes/words) are represented according to their links to communities. We show that SINr-NR and SINr-MF can compete with similar embedding approaches on tasks such as predicting missing links in networks (link prediction) or node features (degree centrality\, PageRank score). Regarding word embeddings\, we show that SINr-NR is a good contender to represent words via word co-occurrence networks. Finally\, we demonstrate the interpretability of SINr-NR on multiple aspects. First with a human evaluation that shows that SINr-NR’s dimensions are to some extent interpretable. Secondly\, by investigating sparsity of vectors\, and how having fewer dimensions may allow interpreting how the dimensions combine and allow sense to emerge.,L&apos;apprentissage de représentations au travers des méthodes de plongements de mots (word embedding) et de graphes (graph embedding) permet des représentations distribuées de l&apos;information. Ces représentations peuvent à leur tour être utilisées en entrée d&apos;algorithmes d&apos;apprentissage automatique. Au cours des deux dernières décennies\, les tâches de plongement de nœuds et de mots sont passées d&apos;approches par factorisation matricielle qui pouvaient être réalisées en quelques minutes à de grands modèles nécessitant des quantités toujours plus importantes de données d’apprentissage et parfois des semaines sur de grandes architectures matérielles. Toutefois\, dans un contexte de réchauffement climatique où la durabilité est une préoccupation essentielle\, il peut être souhaitable de revenir à des méthodes plus frugales comme elles pouvaient l’être par le passé. En outre\, avec l&apos;implication croissante des plongements dans des applications sensibles de l’apprentissage automatique (système judiciaire\, santé)\, le besoin de représentations plus interprétables et explicables s&apos;est manifesté. Pour favoriser l&apos;apprentissage de représentations efficaces et l&apos;interprétabilité\, cette thèse présente Lower Dimension Bipartite Graph Framework (LDBGF)\, un framework de plongements de nœuds capable d’extraire une représentation vectorielle avec le même pipeline de traitement\, à condition que les données proviennent d’un graphe ou de texte issu de grands corpus représentés sous forme de réseaux de cooccurrence. Dans ce cadre\, nous présentons deux implémentations (SINr- NR\, SINr-MF) qui tirent parti de la détection des communautés dans les réseaux pour découvrir un espace latent dans lequel les éléments (nœuds/mots) sont représentés en fonction de leurs liens avec les communautés. Nous montrons que SINr-NR et SINr-MF peuvent rivaliser avec des approches de plongements concurrentes sur des tâches telles que la prédiction des liens manquants dans les réseaux (link prediction) ou certaines caractéristiques des nœuds (centralité de degré\, score PageRank). En ce qui concerne les plongements de mots\, nous montrons que SINr-NR est un bon candidat pour représenter les mots en utilisant les réseaux de cooccurrences de mots. Enfin\, nous démontrons l&apos;interprétabilité de SINr-NR sur plusieurs aspects. Tout d&apos;abord\, une évaluation humaine montre que les dimensions de SINr-NR sont dans une certaine mesure interprétables. Ensuite\, nous étudions la parcimonie des vecteurs. Notamment\, combien un nombre réduit de dimensions peut permettre d&apos;interpréter comment ces dernières se combinent et permettent de dégager un sens.

[Download paper here](https://theses.hal.science/tel-04696544/document)

Recommended citation: Machine Learning [cs.LG]. Le Mans Université, 2024. English. <a target="_blank" href="https://www.theses.fr/2024LEMA1006">&#x27E8;NNT : 2024LEMA1006&#x27E9;</a>