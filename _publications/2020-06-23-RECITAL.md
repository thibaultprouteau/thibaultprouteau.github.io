---
title: "Apprentissage de plongements de mots sur des corpus en langue de spécialité : une étude d'impact"
collection: publications
permalink: /publication/2020-06-23-RECITAL
excerpt: ''
date: 2020-06-23
venue: 'Rencontre des étudiants Chercheurs en Informatique pour le Traitement Automatique de Langues (RECITAL, 22e édition)'
paperurl: 'https://hal.archives-ouvertes.fr/hal-02786198v3/document'
---

Word embedding approaches are state of the art in Natural Language Processing (NLP). In this work, we focus on learning word embeddings for small domain-specific corpora. In particular, we would like to know whether word embeddings learnt over large corpora such as Wikipedia perform better than word embeddings learnt on domain specific corpora. In order to answer this question, we consider two corpora : OHSUMED from the medical field, and SNCF, a technical documentation corpus. After presenting the corpora and evaluating their specificity, we introduce a classification task. We use word embeddings learnt on domain-specific corpora or Wikipedia as input for this task. Our analysis demonstrates that word embeddings learnt on Wikipedia achieve excellent results, even though, in the case of OHSUMED, domain specific word embeddings perform better.

Recommended citation : Valentin Pelloin, Thibault Prouteau (2020). &quot;Apprentissage de plongements de mots sur des corpus en langue de spécialité : une étude d'impact.&quot; <i>6e conférence conjointe Journées d'Études sur la Parole (JEP, 33e édition), Traitement Automatique des Langues Naturelles (TALN, 27e édition), Rencontre des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RÉCITAL, 22e édition).</i>


[Download paper here](https://hal.archives-ouvertes.fr/hal-02786198v3/document)

